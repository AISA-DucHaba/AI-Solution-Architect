{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AISA-DucHaba/AI-Solution-Architect/blob/main/Challenge_AISA_Text_Moderation_Optional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WnEac7Fwdgw"
      },
      "source": [
        "# ðŸŒ» Text Moderation\n",
        "\n",
        "---\n",
        "\n",
        "**THE CHALLENGE:**\n",
        "\n",
        "- Many have expressed the desire to:\n",
        "\n",
        "> **Do my first real-world AI project.**\n",
        "\n",
        "\n",
        "\n",
        "- So, here are real-world projects. I have used the NLP text toxicity measuring project for three enterprise clients. (Total project cost \\$1.2M to \\$2.5M)\n",
        "\n",
        "- It is NOT the same as this Jupyter Notebook, but the concepts are the same.\n",
        "- Unlike the original Notebook, this one has NO code cell.\n",
        "- This challenge is unique to you. You have the freedom to use different libraries or different ML models. It doesn't have to be NLP; it could be LLM, like API to Gemini or Claude. The choice is yours.\n",
        "\n",
        "- Remember, this is an honor system. I trust you will not cheat by looking at the original Notebook. Your integrity is vital in this challenge.\n",
        "\n",
        "- Only refer to the original Notebook if you are about to quit, i.e., unable to move forward.\n",
        "\n",
        "- I will not discuss this challenge during class hours (because not all students want to be challenged, and it is outside the scope of the course).\n",
        "\n",
        "- Have fun coding :-)\n",
        "\n",
        "---\n",
        "\n",
        "- Let's Rock and Roll\n",
        "\n",
        "- **ROLE** defintion by icon:\n",
        "\n",
        "  - ðŸ¤  is AI Solution Architect role.\n",
        "  - ðŸ¤– is AI Scientest role.\n",
        "  - ðŸ˜Ž is Devops role.\n",
        "  - ðŸ¤“ is Data Engineer role.\n",
        "  - ðŸ¤” is AI QA role.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHGKa52qwsp7"
      },
      "source": [
        "## ðŸ¤  Objective\n",
        "\n",
        "- This NLP (Natural Language Processing) AI demonstration aims to prevent profanity, vulgarity, hate speech, violence, sexism, and other offensive language. It is not an act of censorship, as the final UI (User Interface) will give the reader, but not a young reader, the option to click on a label to read the toxic message.\n",
        "\n",
        "- The goal is to create a safer and more respectful environment for you, your colleages, and your family. This NLP app is 1 of 3 hands-on apps from the [\"AI Solution Architect,\"](https://elvtr.com/course/ai-solution-architect?utm_source=instructor&utm_campaign=AISA&utm_content=linkedin) from ELVTR and Duc Haba.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ™ˆ Legal:\n",
        "\n",
        "---\n",
        "\n",
        "- This Python Jupyter Notebook is for sharing with **Friends** in the AISA course by ELVTR.\n",
        "\n",
        "- If you are **NOT** my friend, and I see you. In the best spirit of the **science community**, you may read this Notebook, but be aware that I see you.\n",
        "\n",
        "- Copyrights 2023 and 2024: [GNU GENERAL PUBLIC LICENSE 3.0](https://www.gnu.org/licenses/gpl-3.0.en.html#license-text)"
      ],
      "metadata": {
        "id": "y2GF4K0lcXVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print the time\n",
        "\n",
        "# Check your notebook, and you are in the race..."
      ],
      "metadata": {
        "id": "BRnCZFMSR0L9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUogjldqkhPn"
      },
      "source": [
        "# ðŸ˜Ž Set Up and Verify\n",
        "\n",
        "---\n",
        "\n",
        "- **PRIMARY ROLE:** DevOps Engineer\n",
        "\n",
        "- This section is setting up your environment and verify the server (or laptop) has the correct library and computing power.\n",
        "\n",
        "- I use the Pluto class often in my coding. I created it as an opensource project.\n",
        "\n",
        "- Github: 'https:'\n",
        "\n",
        "- Pluto is **optional** for this project. Pluto has a lot of convience functions that use/write otherwise.\n",
        "\n",
        "- Note: Code cell begin with **\"# prompt:\"** is writen by a GenAI, Copilot or Codey.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install required libraries\n",
        "\n",
        "- NOTE âœ‹: If you run on local laptop or **persistance** platform like, AWS Sagemaker, you need to run pip install just once.\n",
        "\n",
        "- Google Colab is a **non-persistance** platform. Thus you need to install library every time you start up Google Colab.\n",
        "\n",
        "- Hint: The **%%write app.py** is for writing export the code cell for deployment. NOT all code cells are export (because some code are for testing)"
      ],
      "metadata": {
        "id": "wFGEfq66P-Hk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pj2BqKWa1Osn"
      },
      "outputs": [],
      "source": [
        "# use capture to hide the long output\n",
        "%%capture log_pip_install_openai\n",
        "\n",
        "# install the needed lib."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If has error, uncomment and print out the log file\n",
        "# print(log_pip_install_openai)"
      ],
      "metadata": {
        "id": "U2MogmXySWhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: import openai, huggingface client and gradio\n"
      ],
      "metadata": {
        "id": "wNsvTFuhJxeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print out version of openai, gradio and huggingface_hub\n"
      ],
      "metadata": {
        "id": "sRERRYZpS1Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note: I am using/testing with these version.\n",
        "\n",
        "  - openai version: 1.35.14\n",
        "  - gradio version: 4.38.1\n",
        "  - huggingface_hub version: 0.23.4\n",
        "\n",
        "- You don't have to use the exact version but cognizant of them."
      ],
      "metadata": {
        "id": "6R1i47NZTG2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ¤  Install Pluto (Optional)\n",
        "\n",
        "- **PRIMARY ROLE:** AI Solution Arch.\n",
        "\n",
        "- NOTE âœ‹: Once again **pluto class is optional**. You are free to use other lib or none at all.\n",
        "\n",
        "- It is a base class that everyone in the team should use in their Jupyter Notebook."
      ],
      "metadata": {
        "id": "iQ4DvPjRT3-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print git version\n"
      ],
      "metadata": {
        "id": "r2DeeoKBTvRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note: I am using this git version:\n",
        "  - git version 2.34.1"
      ],
      "metadata": {
        "id": "1OxFOHNCURTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: install lfs and track large file *.pkl\n"
      ],
      "metadata": {
        "id": "KhXCeZTiUihl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxuRP5nbojqq"
      },
      "outputs": [],
      "source": [
        "# prompt: print out my environments statistic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAg9QSv6hMQm"
      },
      "source": [
        "- The documentation is at: https://platform.openai.com/docs/api-reference\n",
        "\n",
        "- https://github.com/openai/openai-python\n",
        "\n",
        "- The Notebook set to GPU and High RAM, but you do not need them to run. It maybe slow without GPU and a lot of RAM, but it will fine.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYTj6YmpApba"
      },
      "source": [
        "# ðŸ¤  Access to LLM model: STEP 1\n",
        "---\n",
        "\n",
        "- **PRIMARY ROLE:** AI Solution Architect\n",
        "\n",
        "- NOTES: âœ‹ STOP, define your set of keys before continue\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLElZNzgMi8l"
      },
      "source": [
        "## Define YOUR Keys: âœ‹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3NPJ7l7nlPF"
      },
      "outputs": [],
      "source": [
        "# # update and uncomment with your key\n",
        "# os.environ['openai_key'] = 'sk-...'\n",
        "# os.environ['huggingface_key'] = 'hf_....'\n",
        "# os.environ['kaggle_key'] = 'daabc...'\n",
        "# os.environ['github_key'] = 'ghp_...'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgCpuPolnmPY"
      },
      "source": [
        "# ðŸ¤– Access LLM: STEP 2\n",
        "\n",
        "----\n",
        "\n",
        "- **PRIMARY ROLE:** AI Scientist\n",
        "\n",
        "- **NOTE:** For the challenge you do not have to use OpenAI moderation model. Find other AI model if you like.\n",
        "\n",
        "\n",
        "- Smoke test to see if we can access to the chosen model and run it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSH08CSL96fN"
      },
      "source": [
        "## POC - OpenAI or Your AI model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jNO1cAXNZKr"
      },
      "source": [
        "## POC - Done ðŸ’ƒ\n",
        "---\n",
        "\n",
        "- You just prove the heart of the LLM engine is working.\n",
        "\n",
        "- Technically, you can confidently say the project is \"viable.\"\n",
        "\n",
        "- The crucial part POC is done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcZ0RUl35fY_"
      },
      "source": [
        "### ðŸ¤– AI Scientist Walk About on OpenAI (Optional)\n",
        "\n",
        "\n",
        "- AI Scientist to explore futher on OpenAI models.\n",
        "\n",
        "- Doc at: https://platform.openai.com/docs/api-reference\n",
        "\n",
        "- Check out Assistants\n",
        "\n",
        "- Use Dall-e to draw image\n",
        "\n",
        "I delete code so it up to you.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HW7lY4ET7zb"
      },
      "source": [
        "# ðŸ¤“ Fetch Dataset from Kaggle: STEP 3\n",
        "\n",
        "- **PRIMARY ROLE:** Data Engineer\n",
        "\n",
        "- **NOTE:** For the challenge, you can find different dataset on Kaggle\n",
        "\n",
        "- Dataset on kaggle: link go here...\n",
        "\n",
        "- Goals are:\n",
        "  - download\n",
        "  - import to Pandas Dataframe\n",
        "  - clean\n",
        "  - augment\n",
        "  - inspect\n",
        "  - report on biases\n",
        "  - **AND** whatever you need to do to feel confortable with the datasest."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download"
      ],
      "metadata": {
        "id": "AndgQlqQuRVC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note: You need your kaggle username and access token"
      ],
      "metadata": {
        "id": "TGbgPXyTtckU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import to Pandas"
      ],
      "metadata": {
        "id": "6izTs_92uXvG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean data"
      ],
      "metadata": {
        "id": "APfUKF2Qut8X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save it."
      ],
      "metadata": {
        "id": "aNmhXwKLvmS7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCx5vYanSHsJ"
      },
      "source": [
        "# ðŸ¤“ Investigate data\n",
        "\n",
        "- **PRIMARY ROLE:** Data engineer\n",
        "- Count average word size of more_toxic.\n",
        "- Count average word size of less_toxic.\n",
        "- Plot histogram\n",
        "- Report statistic\n",
        "- Draw word cloud"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count words"
      ],
      "metadata": {
        "id": "-976yJ46w1RM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draw histogram"
      ],
      "metadata": {
        "id": "B7va24DDxriU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report statistic"
      ],
      "metadata": {
        "id": "vkwRj3vlyqXz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draw word cloud"
      ],
      "metadata": {
        "id": "Ql9iQZjuy_Hw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNBretL5cbZD"
      },
      "outputs": [],
      "source": [
        "# redraw them by re-run previous generate_wordcloud cell/command."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ¤” Reports\n",
        "\n",
        "- **PRIMARY ROLE:** AI QA engineer\n",
        "\n",
        "- Work with the Data engineer to write a report and potential data biases\n"
      ],
      "metadata": {
        "id": "ENILHFEQ3Qdq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-TYGDL_AzG7"
      },
      "source": [
        "# ðŸ¤– Write API: Step 4\n",
        "\n",
        "- **PRIMARY ROLE:** AI scientist\n",
        "\n",
        "- Write a few functions to make the API and hook into Gradio and Huggingface."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC2DivZF4grS"
      },
      "source": [
        "## ðŸ¤” Smoke test the functions\n",
        "\n",
        "- **PRIMARY ROLE:** AI QA engineer\n",
        "\n",
        "- QA all the functions above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqiP3ho3JbKW"
      },
      "source": [
        "# ðŸ¤– Define HuggingFace Gradio Interface\n",
        "\n",
        "- **PRIMARY ROLE:** AI scientist\n",
        "\n",
        "- **NOTE:** You don't have to use HuggingFace or Graido. Choose your own deployment platform.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzCOApzwIC7V"
      },
      "source": [
        "# ðŸ¤” QA - Test it locally on Jupyter Notebook: STEP 5\n",
        "\n",
        "- It will failed to test locally if you running VPN\n",
        "\n",
        "- You should see the app run locally/here as if it is on HuggingFace.\n",
        " - https"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwC_rWcNPkVn"
      },
      "source": [
        "# ðŸ¤  Presentation and Review\n",
        "\n",
        "- **PRIMARY ROLE:** AI solution architect\n",
        "- As an AI solution architect, you will review the work above.\n",
        "\n",
        "- The rest of the steps are for DevOps"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ˜Ž Production Deployment\n",
        "\n",
        "- *Duc: I have not clean up this section yet.*\n",
        "\n",
        "- **PRIMARY ROLE:** DevOps engineer\n",
        "\n",
        "- We choose Huggingface website, but in realword it would on AWS or Google Serverless engine or MS Azure servers."
      ],
      "metadata": {
        "id": "3YHQsNl05P21"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anKLQ3g8vlZm"
      },
      "source": [
        "## Write/create required files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsF4xLdREBx8"
      },
      "source": [
        "## Create the HuggingFace page\n",
        "\n",
        "- Choose a unique file-space, like happy_butterfly\n",
        "\n",
        "- First option, do it on huggingface.com website (recomented)\n",
        "\n",
        "- Second option, do it programatically (optional, uncomment below)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dulzFow1AT68"
      },
      "outputs": [],
      "source": [
        "# # second option\n",
        "# api = huggingface_hub.HfApi()\n",
        "# api.create_repo(repo_id=pluto.hface_name, private=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKF1nWC3MRJO"
      },
      "source": [
        "# ðŸ¤” Deploy to HuggingFace Sandbox and QA\n",
        "\n",
        "---\n",
        "\n",
        "- Read the tutorial above if you are confused.\n",
        "\n",
        "- It is easy. \"app.py\" and \"requirements.txt\" are the two files that you need to upload.\n",
        "  - Link to create the app.py file on huggingface web: https:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0BqlE3dGbnq"
      },
      "source": [
        "# ðŸ˜Ž Pull and Push to Github (Optional)\n",
        "\n",
        "- **PRIMARY ROLE:** DevOps engineer\n",
        "\n",
        "**Note:** âœ‹\n",
        "\n",
        "- QA it on this notebook **BEFORE** push it.\n",
        "\n",
        "- If you change any data or files, commit and push it to github. For now, we don't need pull-request, so push it to main or your-branch-name.\n",
        "\n",
        "- I ussualy comment out the section because I don't want to accidental run it (when not ready)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_jLD0Z7AUKk"
      },
      "source": [
        "# That's it. It's dancing time: ðŸ•º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUzE7MfOI1Sl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc807374-5a5f-4fc9-c2ec-ee151139d3f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the end.\n"
          ]
        }
      ],
      "source": [
        "print('the end.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VL5egEhI16n",
        "outputId": "a841660a-522c-429e-9642-810dde1c96b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|-----------------------------------------------------------------------|\n",
            "|    o   \\ o /  _ o         __|    \\ /     |__        o _  \\ o /   o    |\n",
            "|   /|\\    |     /\\   ___\\o   \\o    |    o/    o/__   /\\     |    /|\\   |\n",
            "|   / \\   / \\   | \\  /)  |    ( \\  /o\\  / )    |  (\\  / |   / \\   / \\   |\n",
            "|----------------------------Yahoo_ooo----------------------------------|\n"
          ]
        }
      ],
      "source": [
        "# monty.print_dancing()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2x-NQlhNSD9"
      },
      "source": [
        "# ðŸ¤  Conclusion\n",
        "\n",
        "- Write your conclusion here."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMGfQRqX72En2L2JHNXgyqP",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}