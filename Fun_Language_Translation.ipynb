{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8qFSH1LdtZGP"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNqjAAlX7yETCfYLPGhGSdX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AISA-DucHaba/AI-Solution-Architect/blob/main/Fun_Language_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåª Fun Language Translation, NLP\n",
        "\n",
        "---\n",
        "\n",
        "- Welcome to a game of translation.\n",
        "\n",
        "- We are using NLP on opensource HuggingFace\n",
        "\n",
        "- It shows you how to write the core translation.\n",
        "\n",
        "- The input is **English**\n",
        "\n",
        "- The output is a translation **text** AND the speaking **voice**.\n",
        "\n",
        "- The default is to **Hindi**, but you can change to **other language**.\n",
        "\n",
        "- One idea for the **'group writing story'** with AI/LLMs is at the bottom.\n",
        "\n",
        "- Lastly: Code written by AI begins with the **'# Prompt: '**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "1S8aSThtODaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üôà Legal (because we must)\n",
        "\n",
        "---\n",
        "\n",
        "- This code is for Duc's friends in the AI Solution Architect course.\n",
        "\n",
        "- My friends are free to use, hack, and learn from the code.\n",
        "\n",
        "- To all other, It is Copyright, 2025, by Duc Haba, AND protect by GNU General Public License. https://www.gnu.org/licenses/gpl-3.0.en.html\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0ViulYJ-YR9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Basic check\n",
        "\n",
        "---\n",
        "\n",
        "- Are we OK with the notebook?\n",
        "  - I am using Google Colab, but other Jupyter notebook is fine, e.g. AWS Sagemaker, Microsoft Azure AI, Kaggle, etc.\n",
        "\n",
        "- Do we have sufficient CPU and GPU?\n",
        "  - I am using CPU (8 cores) 51 GB RAM, 230 GB Disk space\n",
        "  - GPU, NVidia, 15 GB RAM."
      ],
      "metadata": {
        "id": "bxgm36LDZtln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print data and time in friendly format for california timezone\n",
        "\n",
        "from datetime import datetime\n",
        "from pytz import timezone\n",
        "\n",
        "# Define the California timezone (Pacific Time)\n",
        "california_tz = timezone('America/Los_Angeles')\n",
        "\n",
        "# Get the current time in UTC\n",
        "utc_now = datetime.utcnow()\n",
        "\n",
        "# Convert the UTC time to the California timezone\n",
        "california_time = utc_now.replace(tzinfo=timezone('UTC')).astimezone(california_tz)\n",
        "\n",
        "# Print the date and time in a friendly format\n",
        "print(california_time.strftime('%Y-%m-%d %H:%M:%S %Z%z'))"
      ],
      "metadata": {
        "id": "S5gXZKd7Paci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: print out system and gpu info\n",
        "\n",
        "!lscpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "TjsHwiAaan7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: login to huggingface\n",
        "# OPTIONAL: You need to do this if you plan to deploy the code on HuggingFace\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "8YzNuLirQmhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Load NLP base model\n",
        "\n",
        "---\n",
        "\n",
        "- You can chose any 'text translation' on HuggingFace, but some of the sytax may change based on the model you selected.\n",
        "\n",
        "- Default model is the: \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "\n",
        "- Link to the model info: https://huggingface.co/Helsinki-NLP/opus-mt-en-hi\n",
        "\n",
        "- There are **1527 Text Translation model from Helsinki**.\n",
        "\n",
        "- Additional NLP translation model from Helsinki. https://huggingface.co/Helsinki-NLP/models"
      ],
      "metadata": {
        "id": "aUAIV_6gbDBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# required lib\n",
        "!pip install transformers\n",
        "!pip install sacremoses"
      ],
      "metadata": {
        "id": "SxjOF-Wufhqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Write python function name \"translate_me\" using the model \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "#\n",
        "# Define new model name here:\n",
        "#\n",
        "_MODEL_NAME = \"Helsinki-NLP/opus-mt-en-hi\"\n",
        "_readable_name = \"English to Hindi\" # OPTIONAL for human to read\n",
        "#\n",
        "tokenizer = MarianTokenizer.from_pretrained(_MODEL_NAME)\n",
        "model = MarianMTModel.from_pretrained(_MODEL_NAME)\n",
        "\n",
        "def translate_me(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    translated = model.generate(**inputs)\n",
        "    return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "#\n",
        "# test it.\n",
        "english_input = \"I love programming.\"\n",
        "print(f'\\n-----\\nModel name: {_MODEL_NAME}\\n')\n",
        "print(f'We are translate from: {_readable_name}')\n",
        "translation_output = translate_me(english_input)\n",
        "print(f'English: {english_input}\\nTranslation: {translation_output}')"
      ],
      "metadata": {
        "id": "QgeWV_4vO7h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test it again.\n",
        "english_input = \"To be, or not to be, that is the question: Whether 'tis nobler in the mind to suffer. The slings and arrows of outrageous fortune, Or to take arms against a sea of troubles.\"\n",
        "translation_output = translate_me(english_input)\n",
        "#\n",
        "print(f'We are translate from: {_readable_name}')\n",
        "print(f'English: {english_input}\\nTranslate: {translation_output}\\n')"
      ],
      "metadata": {
        "id": "pZ1gu0nFO7k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Speak it\n",
        "\n",
        "---\n",
        "\n",
        "- That was easy, so we push forward with asking the notebook to say it."
      ],
      "metadata": {
        "id": "BZGQyeHLhio4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install require lib\n",
        "!pip install gTTS"
      ],
      "metadata": {
        "id": "hN_jaG1oO7n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write python function \"say_it\" to use Notebook to speak Hindi\n",
        "from IPython.display import Audio\n",
        "from gtts import gTTS\n",
        "#\n",
        "#\n",
        "# _out_lang: I manually make this a passing varible, default to Hindi\n",
        "#\n",
        "def say_it(text, _out_lang = 'hi'):\n",
        "    tts = gTTS(text=text, lang=_out_lang)\n",
        "    filename = \"/tmp/hindi_audio.mp3\"    # you can chose any disk drive path and filename\n",
        "    tts.save(filename)\n",
        "    return Audio(filename, autoplay=True)\n",
        "\n",
        "# Example: Test it.\n",
        "say_it(translation_output)"
      ],
      "metadata": {
        "id": "X5YgAyhaVmaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- WOW, we just speak Shakespeare in Hindi"
      ],
      "metadata": {
        "id": "G5iGWTVFiyfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Put it all together\n",
        "\n",
        "---\n",
        "\n",
        "- Combine the texttranslation with the narration into one.\n",
        "\n",
        "- Yes, folks. In other words, it is an Agent AI.\n",
        "\n",
        "- I challenge you to upgrade it an Agentic AI.\n",
        "\n",
        "- Note: If you need to speak multiple languages in the same app, you can create multiple function 'agent_translate_and_speak' with a different name for each translation."
      ],
      "metadata": {
        "id": "EaXyngrKjMcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: write a Python function with documentation to call the translate_me function then call the say_it function\n",
        "# I manually add the '_out_lang = 'hi' parameter. Hindi as the default.\n",
        "\n",
        "def agent_translate_and_speak(text, _out_lang = 'hi' ):\n",
        "  \"\"\"\n",
        "  Translates the given English text to Hindi and speaks the translated text.\n",
        "\n",
        "  Args:\n",
        "    text: The English text to translate and speak.\n",
        "  \"\"\"\n",
        "  translated_text = translate_me(text)\n",
        "  print(f'From: {_readable_name}\\n')\n",
        "  print(f'English: {text}\\nTranslation: {translated_text}\\n')\n",
        "  return say_it(translated_text, _out_lang)\n",
        "\n",
        "# Example usage:\n",
        "english_input = \"Hello, how are you?\"\n",
        "agent_translate_and_speak(english_input)\n"
      ],
      "metadata": {
        "id": "uFzcQeGEj1i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üíÉ üï∫ Step 5: Let's Disco Dancing : New Translation\n",
        "\n",
        "---\n",
        "\n",
        "- When you stop disco dancing, we can try it with different language translation\n",
        "\n",
        "- It is really easy. We just need to redefine the NLP model.\n",
        "\n",
        "- Remember the NLP 1,527 models in Step 2:?\n",
        "  - Here they are again. Additional NLP translation model from Helsinki. https://huggingface.co/Helsinki-NLP/models"
      ],
      "metadata": {
        "id": "xEqntYuNlwHx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hindi to English\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "y37vLeu2tvel"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define new language (NLP) model\n",
        "#\n",
        "# YOU chose.\n",
        "# So I choose, Hindi to English\n",
        "#\n",
        "_MODEL_NAME = \"Helsinki-NLP/opus-mt-hi-en\"\n",
        "_out_lang = 'en'                    # speak output in this language\n",
        "_readable_name = \"Hindi to English\" # OPTIONAL for human to read\n",
        "#\n",
        "tokenizer = MarianTokenizer.from_pretrained(_MODEL_NAME)\n",
        "model = MarianMTModel.from_pretrained(_MODEL_NAME)"
      ],
      "metadata": {
        "id": "_0jvAQE6t0aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test it\n",
        "_input_text = '‡§π‡•à‡§≤‡•ã, ‡§§‡•Å‡§Æ ‡§ï‡•à‡§∏‡•á ‡§π‡•ã?'\n",
        "agent_translate_and_speak(_input_text, _out_lang = _out_lang)"
      ],
      "metadata": {
        "id": "sVgHBag9t0dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## English to French\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "8qFSH1LdtZGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define new language (NLP) model\n",
        "#\n",
        "# YOU chose.\n",
        "# So I choose, English to French\n",
        "#\n",
        "_MODEL_NAME = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "_out_lang = 'fr'                     # speak output in this language\n",
        "_readable_name = \"English to French\" # OPTIONAL for human to read\n",
        "#\n",
        "tokenizer = MarianTokenizer.from_pretrained(_MODEL_NAME)\n",
        "model = MarianMTModel.from_pretrained(_MODEL_NAME)"
      ],
      "metadata": {
        "id": "ysScAy6Ej1sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test it\n",
        "_input_text = 'The quick brown fox jumps over the lazy dog.'\n",
        "agent_translate_and_speak(_input_text, _out_lang = _out_lang)"
      ],
      "metadata": {
        "id": "4aVw7L5BVmjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## English to Bengali\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "BJacrsp2v7tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define new language (NLP) model\n",
        "#\n",
        "# YOU chose.\n",
        "# So I choose, English to Bengali\n",
        "#\n",
        "# NOTICE: I am NOT usign Helsinki-NLP, but from 'shhossain'.\n",
        "#\n",
        "_MODEL_NAME = \"shhossain/opus-mt-en-to-bn\"\n",
        "_out_lang = 'bn'                          # speak output in this language\n",
        "_readable_name = \"English to Bangali\"     # OPTIONAL for human to read\n",
        "#\n",
        "tokenizer = MarianTokenizer.from_pretrained(_MODEL_NAME)\n",
        "model = MarianMTModel.from_pretrained(_MODEL_NAME)"
      ],
      "metadata": {
        "id": "gYfvM8mbv8Dm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test it\n",
        "_input_text = 'Good evening. I would like to order two pizza. One with chicken curry and the other with lamb masala.'\n",
        "agent_translate_and_speak(_input_text, _out_lang = _out_lang)"
      ],
      "metadata": {
        "id": "S-6CAYnRv8HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The End."
      ],
      "metadata": {
        "id": "PjOQlDixcJ9T"
      }
    }
  ]
}